{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "123345c1-7e82-4ff4-a117-c5a3f9918e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential , load_model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "from PIL import Image, ImageTk\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f85e406e-7732-40bd-af26-01f2eefc1466",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = r\"C:\\Users\\Tarun Singh\\Green AI\\DataSet_Wildfire\\train\"\n",
    "valid_dir = r\"C:\\Users\\Tarun Singh\\Green AI\\DataSet_Wildfire\\valid\"\n",
    "test_dir = r\"C:\\Users\\Tarun Singh\\Green AI\\DataSet_Wildfire\\test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d916445-85a6-429a-aa78-bcf65311c0a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 30250 images belonging to 2 classes.\n",
      "Found 6300 images belonging to 2 classes.\n",
      "Found 6300 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "valid_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(train_dir, target_size=(64, 64), batch_size=32, class_mode='binary')\n",
    "valid_generator = valid_datagen.flow_from_directory(valid_dir, target_size=(64, 64), batch_size=32, class_mode='binary')\n",
    "test_generator = test_datagen.flow_from_directory(test_dir, target_size=(64, 64), batch_size=32, class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb63dd29-0405-4f76-a8d5-dabe8589bcc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Apps\\Anaconda\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 3)),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Conv2D(64,(3,3),activation = 'relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128,activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1,activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a316a21-ac61-45cc-864e-999c8b18109d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e308938-487c-494b-91fd-8dc431d27b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "defde43a-44ed-47aa-a6c2-3d1ed281877a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Apps\\Anaconda\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "\u001b[1m946/946\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 142ms/step - accuracy: 0.8509 - loss: 0.3167 - val_accuracy: 0.9471 - val_loss: 0.1434\n",
      "Epoch 2/4\n",
      "\u001b[1m946/946\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m223s\u001b[0m 236ms/step - accuracy: 0.9324 - loss: 0.1792 - val_accuracy: 0.9505 - val_loss: 0.1296\n",
      "Epoch 3/4\n",
      "\u001b[1m946/946\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 127ms/step - accuracy: 0.9425 - loss: 0.1570 - val_accuracy: 0.9548 - val_loss: 0.1246\n",
      "Epoch 4/4\n",
      "\u001b[1m946/946\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 128ms/step - accuracy: 0.9468 - loss: 0.1439 - val_accuracy: 0.9406 - val_loss: 0.1503\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_generator,epochs=4,validation_data=valid_generator,verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5db59b9e-199f-4017-87b3-fe4119c44c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "from PIL import ImageTk, Image\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import  load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "312e7955-8b67-490e-8b98-a651de3679e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save('wildfire_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad037b07-bc83-4098-93ef-66c3412d1a37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "model = load_model('wildfire_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d8c7ff5d-cee4-49f3-94de-37ac2afd571e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gradio in d:\\apps\\anaconda\\lib\\site-packages (5.11.0)\n",
      "Requirement already satisfied: aiofiles<24.0,>=22.0 in d:\\apps\\anaconda\\lib\\site-packages (from gradio) (23.2.1)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in d:\\apps\\anaconda\\lib\\site-packages (from gradio) (4.2.0)\n",
      "Requirement already satisfied: fastapi<1.0,>=0.115.2 in d:\\apps\\anaconda\\lib\\site-packages (from gradio) (0.115.6)\n",
      "Requirement already satisfied: ffmpy in d:\\apps\\anaconda\\lib\\site-packages (from gradio) (0.5.0)\n",
      "Requirement already satisfied: gradio-client==1.5.3 in d:\\apps\\anaconda\\lib\\site-packages (from gradio) (1.5.3)\n",
      "Requirement already satisfied: httpx>=0.24.1 in d:\\apps\\anaconda\\lib\\site-packages (from gradio) (0.28.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.25.1 in d:\\apps\\anaconda\\lib\\site-packages (from gradio) (0.27.1)\n",
      "Requirement already satisfied: jinja2<4.0 in d:\\apps\\anaconda\\lib\\site-packages (from gradio) (3.1.4)\n",
      "Requirement already satisfied: markupsafe~=2.0 in d:\\apps\\anaconda\\lib\\site-packages (from gradio) (2.1.3)\n",
      "Requirement already satisfied: numpy<3.0,>=1.0 in d:\\apps\\anaconda\\lib\\site-packages (from gradio) (1.26.4)\n",
      "Requirement already satisfied: orjson~=3.0 in d:\\apps\\anaconda\\lib\\site-packages (from gradio) (3.10.14)\n",
      "Requirement already satisfied: packaging in d:\\apps\\anaconda\\lib\\site-packages (from gradio) (23.2)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in d:\\apps\\anaconda\\lib\\site-packages (from gradio) (2.2.2)\n",
      "Requirement already satisfied: pillow<12.0,>=8.0 in d:\\apps\\anaconda\\lib\\site-packages (from gradio) (10.3.0)\n",
      "Requirement already satisfied: pydantic>=2.0 in d:\\apps\\anaconda\\lib\\site-packages (from gradio) (2.5.3)\n",
      "Requirement already satisfied: pydub in d:\\apps\\anaconda\\lib\\site-packages (from gradio) (0.25.1)\n",
      "Requirement already satisfied: python-multipart>=0.0.18 in d:\\apps\\anaconda\\lib\\site-packages (from gradio) (0.0.20)\n",
      "Requirement already satisfied: pyyaml<7.0,>=5.0 in d:\\apps\\anaconda\\lib\\site-packages (from gradio) (6.0.1)\n",
      "Requirement already satisfied: ruff>=0.2.2 in d:\\apps\\anaconda\\lib\\site-packages (from gradio) (0.9.0)\n",
      "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in d:\\apps\\anaconda\\lib\\site-packages (from gradio) (0.1.6)\n",
      "Requirement already satisfied: semantic-version~=2.0 in d:\\apps\\anaconda\\lib\\site-packages (from gradio) (2.10.0)\n",
      "Requirement already satisfied: starlette<1.0,>=0.40.0 in d:\\apps\\anaconda\\lib\\site-packages (from gradio) (0.41.3)\n",
      "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in d:\\apps\\anaconda\\lib\\site-packages (from gradio) (0.13.2)\n",
      "Requirement already satisfied: typer<1.0,>=0.12 in d:\\apps\\anaconda\\lib\\site-packages (from gradio) (0.15.1)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in d:\\apps\\anaconda\\lib\\site-packages (from gradio) (4.11.0)\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in d:\\apps\\anaconda\\lib\\site-packages (from gradio) (0.34.0)\n",
      "Requirement already satisfied: fsspec in d:\\apps\\anaconda\\lib\\site-packages (from gradio-client==1.5.3->gradio) (2024.3.1)\n",
      "Requirement already satisfied: websockets<15.0,>=10.0 in d:\\apps\\anaconda\\lib\\site-packages (from gradio-client==1.5.3->gradio) (14.1)\n",
      "Requirement already satisfied: idna>=2.8 in d:\\apps\\anaconda\\lib\\site-packages (from anyio<5.0,>=3.0->gradio) (3.7)\n",
      "Requirement already satisfied: sniffio>=1.1 in d:\\apps\\anaconda\\lib\\site-packages (from anyio<5.0,>=3.0->gradio) (1.3.0)\n",
      "Requirement already satisfied: certifi in d:\\apps\\anaconda\\lib\\site-packages (from httpx>=0.24.1->gradio) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in d:\\apps\\anaconda\\lib\\site-packages (from httpx>=0.24.1->gradio) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in d:\\apps\\anaconda\\lib\\site-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
      "Requirement already satisfied: filelock in d:\\apps\\anaconda\\lib\\site-packages (from huggingface-hub>=0.25.1->gradio) (3.13.1)\n",
      "Requirement already satisfied: requests in d:\\apps\\anaconda\\lib\\site-packages (from huggingface-hub>=0.25.1->gradio) (2.32.2)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in d:\\apps\\anaconda\\lib\\site-packages (from huggingface-hub>=0.25.1->gradio) (4.66.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\apps\\anaconda\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\apps\\anaconda\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in d:\\apps\\anaconda\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2023.3)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in d:\\apps\\anaconda\\lib\\site-packages (from pydantic>=2.0->gradio) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.6 in d:\\apps\\anaconda\\lib\\site-packages (from pydantic>=2.0->gradio) (2.14.6)\n",
      "Requirement already satisfied: click>=8.0.0 in d:\\apps\\anaconda\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in d:\\apps\\anaconda\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in d:\\apps\\anaconda\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (13.3.5)\n",
      "Requirement already satisfied: colorama in d:\\apps\\anaconda\\lib\\site-packages (from click>=8.0.0->typer<1.0,>=0.12->gradio) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in d:\\apps\\anaconda\\lib\\site-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.16.0)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in d:\\apps\\anaconda\\lib\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in d:\\apps\\anaconda\\lib\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.15.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\apps\\anaconda\\lib\\site-packages (from requests->huggingface-hub>=0.25.1->gradio) (2.0.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\apps\\anaconda\\lib\\site-packages (from requests->huggingface-hub>=0.25.1->gradio) (2.2.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in d:\\apps\\anaconda\\lib\\site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9a45b800-bea6-4b41-830d-1aab59b2876e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 734ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "model = load_model('wildfire_model.h5')\n",
    "\n",
    "def predict_image(img):\n",
    "    img = img.resize((64, 64))\n",
    "    img_array = np.array(img) / 255.0\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    prediction = model.predict(img_array)[0][0]\n",
    "    result = \"Wildfire\" if prediction > 0.5 else \"No Wildfire\"\n",
    "    return result\n",
    "\n",
    "iface = gr.Interface(\n",
    "    fn=predict_image,\n",
    "    inputs=gr.Image(type=\"pil\"),  # Updated input definition\n",
    "    outputs=\"text\",\n",
    "    title=\"Forest Fire Detection\",\n",
    "    description=\"Upload an image to predict whether it contains a wildfire.\"\n",
    ")\n",
    "\n",
    "iface.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50fe2a44-7020-4a15-b336-f44a605df46e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5150c8d0-20dc-4c7a-9b50-2a8991e51ab2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
